{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MODEL = ../resources/FP32/mobilenet-ssd.xml\n",
    "%env LABELS = ../resources/labels.txt\n",
    "%env DEVICE = CPU\n",
    "%env UI = false\n",
    "%env LOOP = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit persons to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "##########################################################\n",
    "# INCLUDES\n",
    "##########################################################\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import cv2\n",
    "import numpy\n",
    "import time\n",
    "import datetime\n",
    "import collections\n",
    "import threading\n",
    "import queue\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from inference import Network\n",
    "\n",
    "##########################################################\n",
    "# CONSTANTS\n",
    "##########################################################\n",
    "\n",
    "CONFIG_FILE = '../resources/config.json'\n",
    "CONF_VIDEODIR = '../UI/resources/video_frames/'\n",
    "CONF_DATAJSON_FILE = '../UI/resources/video_data/data.json'\n",
    "CONF_VIDEOJSON_FILE = '../UI/resources/video_data/videolist.json'\n",
    "CPU_EXTENSION = ''\n",
    "TARGET_DEVICE = 'CPU'\n",
    "STATS_WINDOW_NAME = 'Statistics'\n",
    "CAM_WINDOW_NAME_TEMPLATE = 'Video {}'\n",
    "PROB_THRESHOLD = 0.145\n",
    "FRAME_THRESHOLD = 5\n",
    "WINDOW_COLUMNS = 3\n",
    "LOOP_VIDEO = False\n",
    "UI_OUTPUT = False\n",
    "is_async_mode = True\n",
    "\n",
    "##########################################################\n",
    "# GLOBALS\n",
    "##########################################################\n",
    "\n",
    "model_xml = ''\n",
    "model_bin = ''\n",
    "labels_file = ''\n",
    "videoCaps = []\n",
    "videoCapsJson = []\n",
    "display_lock = threading.Lock()\n",
    "log_lock = threading.Lock()\n",
    "frames = 0\n",
    "frameNames = []\n",
    "numVids = 20000\n",
    "accepted_devices = ['CPU', 'GPU', 'MYRIAD', 'HETERO:FPGA,CPU', 'HDDL']\n",
    "\n",
    "##########################################################\n",
    "# CLASSES\n",
    "##########################################################\n",
    "\n",
    "\n",
    "class FrameInfo:\n",
    "    def __init__(self, frameNo=None, count=None, timestamp=None):\n",
    "        self.frameNo = frameNo\n",
    "        self.count = count\n",
    "        self.timestamp = timestamp\n",
    "\n",
    "\n",
    "class VideoCap:\n",
    "    def __init__(self, cap, req_label, cap_name, is_cam):\n",
    "        self.cap = cap\n",
    "        self.req_label = req_label\n",
    "        self.cap_name = cap_name\n",
    "        self.is_cam = is_cam\n",
    "        self.cur_frame = numpy.array([], dtype='uint8')\n",
    "        self.initial_w = 0\n",
    "        self.initial_h = 0\n",
    "        self.frames = 0\n",
    "        self.cur_frame_count = 0\n",
    "        self.total_count = 0\n",
    "        self.last_correct_count = 0\n",
    "        self.candidate_count = 0\n",
    "        self.candidate_confidence = 0\n",
    "        self.closed = False\n",
    "        self.countAtFrame = []\n",
    "        self.video = None\n",
    "        self.frame = None\n",
    "\n",
    "        if not is_cam:\n",
    "            self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        else:\n",
    "            self.fps = 0\n",
    "\n",
    "        self.videoName = cap_name + \"_inferred.mp4\"\n",
    "\n",
    "    def init_vw(self, h, w, fps):\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        self.video = cv2.VideoWriter(os.path.join('../resources', self.videoName),\n",
    "                                     self.fourcc, fps, (w, h), True)\n",
    "        if not self.video.isOpened():\n",
    "            print(\"Could not open for write\" + self.videoName)\n",
    "            sys.exit(1)\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# FUNCTIONS\n",
    "##########################################################\n",
    "\n",
    "def env_parser():\n",
    "    global TARGET_DEVICE, model_xml, labels_file, CPU_EXTENSION, UI_OUTPUT, numVids, LOOP_VIDEO, is_async_mode\n",
    "    if 'DEVICE' in os.environ:\n",
    "        TARGET_DEVICE = os.environ['DEVICE']\n",
    "    if 'MODEL' in os.environ:\n",
    "        model_xml = os.environ['MODEL']\n",
    "    if 'LABELS' in os.environ:\n",
    "        labels_file = os.environ['LABELS']\n",
    "    if 'DEVICE' in os.environ:\n",
    "        TARGET_DEVICE = os.environ['DEVICE']\n",
    "    if 'CPU_EXTENSION' in os.environ:\n",
    "        CPU_EXTENSION = os.environ['CPU_EXTENSION']\n",
    "    if 'UI' in os.environ:\n",
    "        ui = os.environ['UI']\n",
    "        if ui == \"true\":\n",
    "            UI_OUTPUT = True\n",
    "\n",
    "    if 'LOOP' in os.environ:\n",
    "        lp = os.environ['LOOP']\n",
    "        if lp == \"true\":\n",
    "            LOOP_VIDEO = True\n",
    "        if lp == \"false\":\n",
    "            LOOP_VIDEO = False\n",
    "    if 'NUM_VIDEOS' in os.environ:\n",
    "        numVids = int(os.environ['NUM_VIDEOS'])\n",
    "    if 'FLAG' in os.environ:\n",
    "        async_mode = os.environ['FLAG']\n",
    "        if async_mode == \"async\":\n",
    "            is_async_mode = True\n",
    "        else:\n",
    "            is_async_mode = False\n",
    "\n",
    "\n",
    "def check_args():\n",
    "    # ArgumentParser checks model and labels by default right now\n",
    "    if model_xml == '':\n",
    "        print(\"You need to specify the path to the .xml file\")\n",
    "        print(\"Use -m MODEL or --model MODEL\")\n",
    "        sys.exit(11)\n",
    "    if labels_file == '':\n",
    "        print(\"You need to specify the path to the labels file\")\n",
    "        print(\"Use -l LABELS or --labels LABELS\")\n",
    "        sys.exit(12)\n",
    "\n",
    "    global TARGET_DEVICE\n",
    "    if 'MULTI' not in TARGET_DEVICE and TARGET_DEVICE not in accepted_devices:\n",
    "        print(\"Unsupported device: \" + TARGET_DEVICE)\n",
    "        sys.exit(13)\n",
    "    elif 'MULTI' in TARGET_DEVICE:\n",
    "        target_devices = TARGET_DEVICE.split(':')[1].split(',')\n",
    "        for multi_device in target_devices:\n",
    "            if multi_device not in accepted_devices:\n",
    "                print(\"Unsupported device: \" + TARGET_DEVICE)\n",
    "                sys.exit(13)\n",
    "\n",
    "    if numVids < 1:\n",
    "        print(\"Please set NUM_VIDEOS to at least 1\")\n",
    "        sys.exit(14)\n",
    "\n",
    "\n",
    "def parse_conf_file():\n",
    "    \"\"\"\n",
    "        Parses the configuration file.\n",
    "        Reads videoCaps\n",
    "    \"\"\"\n",
    "    assert os.path.isfile(CONFIG_FILE), \"{} file doesn't exist\".format(CONFIG_FILE)\n",
    "    config = json.loads(open(CONFIG_FILE).read())\n",
    "    cnt = 0\n",
    "    for idx, item in enumerate(config['inputs']):\n",
    "        if cnt < numVids:\n",
    "            if item['video'].isdigit():\n",
    "                videoCap = VideoCap(cv2.VideoCapture(int(item['video'])),\n",
    "                                    item['label'],\n",
    "                                    CAM_WINDOW_NAME_TEMPLATE.format(idx),\n",
    "                                    True)\n",
    "            else:\n",
    "                if os.path.isfile(item['video']):\n",
    "                    videoCap = VideoCap(cv2.VideoCapture(item['video']),\n",
    "                                        item['label'],\n",
    "                                        CAM_WINDOW_NAME_TEMPLATE.format(idx),\n",
    "                                        False)\n",
    "                else:\n",
    "                    print(\"Couldn't find \" + item['video'])\n",
    "                    sys.exit(3)\n",
    "            videoCaps.append(videoCap)\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for vc in videoCaps:\n",
    "        if not vc.cap.isOpened():\n",
    "            print(\"Could not open for reading \" + vc.cap_name)\n",
    "            sys.exit(2)\n",
    "\n",
    "\n",
    "def arrange_windows(width, height):\n",
    "    \"\"\"\n",
    "        Arranges the windows so they are not overlapping\n",
    "        Also starts the display threads\n",
    "    \"\"\"\n",
    "    spacer = 25\n",
    "    cols = 0\n",
    "    rows = 0\n",
    "\n",
    "    # Arrange video windows\n",
    "    for idx in range(len(videoCaps)):\n",
    "        if cols == WINDOW_COLUMNS:\n",
    "            cols = 0\n",
    "            rows += 1\n",
    "        cv2.namedWindow(CAM_WINDOW_NAME_TEMPLATE.format(idx),\n",
    "                        cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.moveWindow(CAM_WINDOW_NAME_TEMPLATE.format(idx),\n",
    "                       (spacer + width) * cols, (spacer + height) * rows)\n",
    "        cols += 1\n",
    "\n",
    "    # Arrange statistics window\n",
    "    if cols == WINDOW_COLUMNS:\n",
    "        cols = 0\n",
    "        rows += 1\n",
    "    cv2.namedWindow(STATS_WINDOW_NAME, cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.moveWindow(STATS_WINDOW_NAME, (spacer + width) * cols,\n",
    "                   (spacer + height) * rows)\n",
    "\n",
    "\n",
    "def saveJSON():\n",
    "    \"\"\"\n",
    "        This JSON contains info about current and total object count\n",
    "    \"\"\"\n",
    "    global videoCapsJson\n",
    "    if UI_OUTPUT:\n",
    "        dataJSON = open(CONF_DATAJSON_FILE, \"w\")\n",
    "        if not os.access(CONF_DATAJSON_FILE, os.W_OK):\n",
    "            print(\"Could not open dataJSON file for writing\")\n",
    "            return 5\n",
    "\n",
    "        videoJSON = open(CONF_VIDEOJSON_FILE, \"w\")\n",
    "        if not os.access(CONF_VIDEOJSON_FILE, os.W_OK):\n",
    "            print(\"Could not open videoJSON file for writing\")\n",
    "            return 5\n",
    "\n",
    "        dataJSON.write(\"{\\n\")\n",
    "        videoJSON.write(\"{\\n\")\n",
    "        vsz = len(videoCapsJson)\n",
    "        for i in range(vsz):\n",
    "            if len(videoCapsJson[i].countAtFrame) > 0:\n",
    "                dataJSON.write(\"\\t\\\"Video_\" + str(i + 1) + \"\\\": {\\n\")\n",
    "                fsz = len(videoCapsJson[i].countAtFrame) - 1\n",
    "                for j in range(fsz):\n",
    "                    strt = \"\\t\\t\\\"%d\\\": {\\n\\t\\t\\t\\\"count\\\":\\\"%d\\\",\\n\\t\\t\\t\\\"\" \\\n",
    "                           \"time\\\":\\\"%s\\\"\\n\\t\\t},\\n\" % \\\n",
    "                           (videoCapsJson[i].countAtFrame[j].frameNo,\n",
    "                            videoCapsJson[i].countAtFrame[j].count,\n",
    "                            videoCapsJson[i].countAtFrame[j].timestamp)\n",
    "                    dataJSON.write(strt)\n",
    "                strt = \"\\t\\t\\\"%d\\\": {\\n\\t\\t\\t\\\"count\\\":\\\"%d\\\",\\n\\t\\t\\t\\\"\" \\\n",
    "                       \"time\\\":\\\"%s\\\"\\n\\t\\t}\\n\" % \\\n",
    "                       (videoCapsJson[i].countAtFrame[fsz].frameNo,\n",
    "                        videoCapsJson[i].countAtFrame[fsz].count,\n",
    "                        videoCapsJson[i].countAtFrame[fsz].timestamp)\n",
    "                dataJSON.write(strt)\n",
    "                dataJSON.write(\"\\t},\\n\")\n",
    "\n",
    "        dataJSON.write(\"\\t\\\"totals\\\": {\\n\")\n",
    "        for i in range(vsz - 1):\n",
    "            dataJSON.write(\"\\t\\t\\\"Video_\" + str(i + 1) + \"\\\": \\\"\" +\n",
    "                           str(videoCapsJson[i].total_count) + \"\\\",\\n\")\n",
    "\n",
    "        i = vsz - 1\n",
    "        dataJSON.write(\"\\t\\t\\\"Video_\" + str(i + 1) + \"\\\": \\\"\" +\n",
    "                       str(videoCapsJson[i].total_count) + \"\\\"\\n\")\n",
    "        dataJSON.write(\"\\t}\\n\")\n",
    "        dataJSON.write(\"}\")\n",
    "        dataJSON.close()\n",
    "\n",
    "        sz = len(frameNames) - 1\n",
    "        for i in range(sz):\n",
    "            videoJSON.write(\n",
    "                \"\\t\\\"\" + str(i + 1) + \"\\\":\\\"\" + str(frameNames[i]) + \"\\\",\\n\")\n",
    "\n",
    "        i = sz\n",
    "        videoJSON.write(\n",
    "            \"\\t\\\"\" + str(i + 1) + \"\\\":\\\"\" + str(frameNames[i]) + \"\\\"\\n\")\n",
    "        videoJSON.write(\"}\")\n",
    "        videoJSON.close()\n",
    "\n",
    "        return 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Plugin initialization for specified device and load extensions library\n",
    "    global rolling_log\n",
    "    global TARGET_DEVICE\n",
    "    global videoCapsJson\n",
    "    global is_async_mode\n",
    "\n",
    "    env_parser()\n",
    "    check_args()\n",
    "    parse_conf_file()\n",
    "\n",
    "    # Initialize the class\n",
    "    infer_network = Network()\n",
    "    # Load the network to IE Plugin\n",
    "    n, c, h, w = infer_network.load_model(model_xml, TARGET_DEVICE, 1, 1, 2,\n",
    "                                          CPU_EXTENSION)[1]\n",
    "    minFPS = min([i.cap.get(cv2.CAP_PROP_FPS) for i in videoCaps])\n",
    "    for vc in videoCaps:\n",
    "        vc.init_vw(h, w, minFPS)\n",
    "\n",
    "    statsWidth = w if w > 345 else 345\n",
    "    statsHeight = h if h > (len(videoCaps) * 20 + 15) else (\n",
    "                len(videoCaps) * 20 + 15)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    statsVideo = cv2.VideoWriter(os.path.join('../resources', 'Statistics.mp4'),\n",
    "                                 fourcc, minFPS, (statsWidth, statsHeight),\n",
    "                                 True)\n",
    "    if not statsVideo.isOpened():\n",
    "        print(\"Couldn't open stats video for writing\")\n",
    "        sys.exit(4)\n",
    "\n",
    "    # Read the labels file\n",
    "    if labels_file:\n",
    "        with open(labels_file, 'r') as f:\n",
    "            labels_map = [x.strip() for x in f]\n",
    "    else:\n",
    "        labels_map = None\n",
    "\n",
    "    # Init a rolling log to store events\n",
    "    rolling_log_size = int((h - 15) / 20)\n",
    "    rolling_log = collections.deque(maxlen=rolling_log_size)\n",
    "\n",
    "    # Init inference request IDs\n",
    "    cur_request_id = 0\n",
    "    next_request_id = 1\n",
    "\n",
    "    if not UI_OUTPUT:\n",
    "        # Arrange windows so they are not overlapping\n",
    "        arrange_windows(w, h)\n",
    "        print(\"To stop the execution press Esc button\")\n",
    "\n",
    "    for idx, vc in enumerate(videoCaps):\n",
    "        vc.start_time = datetime.datetime.now()\n",
    "        vc.pos = idx\n",
    "\n",
    "    if UI_OUTPUT:\n",
    "        videoCapsJson = videoCaps.copy()\n",
    "\n",
    "    if is_async_mode:\n",
    "        print(\"Application running in async mode...\")\n",
    "    else:\n",
    "        print(\"Application running in sync mode...\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # If all video captures are closed stop the loop\n",
    "        no_more_data = [videoCap.closed for videoCap in videoCaps]\n",
    "        # loop over all video captures\n",
    "        for idx, videoCapInfer in enumerate(videoCaps):\n",
    "\n",
    "            # read the next frame\n",
    "            vfps = int(round(videoCapInfer.cap.get(cv2.CAP_PROP_FPS)))\n",
    "            for i in range(0, int(round(vfps / minFPS))):\n",
    "                ret, frame = videoCapInfer.cap.read()\n",
    "                videoCapInfer.cur_frame_count += 1\n",
    "                # If the read failed close the program\n",
    "                if not ret:\n",
    "                    no_more_data[idx] = True\n",
    "                    break\n",
    "\n",
    "            if no_more_data[idx]:\n",
    "                if UI_OUTPUT:\n",
    "                    videoCaps.pop(idx)\n",
    "                    continue\n",
    "                else:\n",
    "                    stream_end_frame = np.zeros((h, w, 1), dtype='uint8')\n",
    "                    cv2.putText(stream_end_frame,\n",
    "                                \"Input file {} has ended\".format(\n",
    "                                    videoCapInfer.cap_name),\n",
    "                                (20, 150),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255),\n",
    "                                1)\n",
    "                    cv2.imshow(videoCapInfer.cap_name, stream_end_frame)\n",
    "                    cv2.waitKey(1)\n",
    "                    videoCaps.pop(idx)\n",
    "                    continue\n",
    "            # Copy the current frame for later use\n",
    "            videoCapInfer.cur_frame = frame.copy()\n",
    "            videoCapInfer.initial_w = videoCapInfer.cap.get(3)\n",
    "            videoCapInfer.initial_h = videoCapInfer.cap.get(4)\n",
    "            # Resize and change the data layout so it is compatible\n",
    "            in_frame = cv2.resize(videoCapInfer.cur_frame, (w, h))\n",
    "            in_frame = in_frame.transpose(\n",
    "                (2, 0, 1))  # Change data layout from HWC to CHW\n",
    "            in_frame = in_frame.reshape((n, c, h, w))\n",
    "\n",
    "            infer_start = datetime.datetime.now()\n",
    "            if is_async_mode:\n",
    "                # Async enabled and only one video capture\n",
    "                infer_network.exec_net(next_request_id, in_frame)\n",
    "                if len(videoCaps) == 1:\n",
    "                    videoCapResult = videoCapInfer\n",
    "                # Async enabled and more than one video capture\n",
    "                else:\n",
    "                    # Get previous index\n",
    "                    videoCapResult = videoCaps[\n",
    "                        idx - 1 if idx - 1 >= 0 else len(videoCaps) - 1]\n",
    "            else:\n",
    "                # Async disabled\n",
    "                infer_network.exec_net(next_request_id, in_frame)\n",
    "                videoCapResult = videoCapInfer\n",
    "\n",
    "            if infer_network.wait(cur_request_id) == 0:\n",
    "                infer_end = datetime.datetime.now()\n",
    "                res = infer_network.get_output(cur_request_id)\n",
    "                infer_duration = infer_end - infer_start\n",
    "                current_count = 0\n",
    "                # Parse detection results of the current request\n",
    "                for obj in res[0][0]:\n",
    "                    class_id = int(obj[1])\n",
    "                    # Draw only objects when probability more than specified threshold\n",
    "                    if (obj[2] > PROB_THRESHOLD and\n",
    "                            videoCapResult.req_label in labels_map and\n",
    "                            labels_map.index(\n",
    "                                videoCapResult.req_label) == class_id - 1):\n",
    "                        current_count += 1\n",
    "                        xmin = int(obj[3] * videoCapResult.initial_w)\n",
    "                        ymin = int(obj[4] * videoCapResult.initial_h)\n",
    "                        xmax = int(obj[5] * videoCapResult.initial_w)\n",
    "                        ymax = int(obj[6] * videoCapResult.initial_h)\n",
    "                        # Draw box\n",
    "                        cv2.rectangle(videoCapResult.cur_frame, (xmin, ymin),\n",
    "                                      (xmax, ymax), (0, 255, 0), 4, 16)\n",
    "\n",
    "                if videoCapResult.candidate_count is current_count:\n",
    "                    videoCapResult.candidate_confidence += 1\n",
    "                else:\n",
    "                    videoCapResult.candidate_confidence = 0\n",
    "                    videoCapResult.candidate_count = current_count\n",
    "\n",
    "                if videoCapResult.candidate_confidence is FRAME_THRESHOLD:\n",
    "                    videoCapResult.candidate_confidence = 0\n",
    "                    if current_count > videoCapResult.last_correct_count:\n",
    "                        videoCapResult.total_count += current_count - videoCapResult.last_correct_count\n",
    "\n",
    "                    if current_count is not videoCapResult.last_correct_count:\n",
    "                        if UI_OUTPUT:\n",
    "                            currtime = datetime.datetime.now().strftime(\n",
    "                                \"%H:%M:%S\")\n",
    "                            fr = FrameInfo(videoCapResult.frames, current_count,\n",
    "                                           currtime)\n",
    "                            videoCapResult.countAtFrame.append(fr)\n",
    "\n",
    "                        new_objects = current_count - videoCapResult.last_correct_count\n",
    "                        for _ in range(new_objects):\n",
    "                            string = \"{} - {} detected on {}\". \\\n",
    "                                format(time.strftime(\"%H:%M:%S\"),\n",
    "                                       videoCapResult.req_label,\n",
    "                                       videoCapResult.cap_name)\n",
    "                            rolling_log.append(string)\n",
    "\n",
    "                    videoCapResult.frames += 1\n",
    "                    videoCapResult.last_correct_count = current_count\n",
    "                else:\n",
    "                    videoCapResult.frames += 1\n",
    "\n",
    "                videoCapResult.cur_frame = cv2.resize(videoCapResult.cur_frame,\n",
    "                                                      (w, h))\n",
    "\n",
    "                if UI_OUTPUT:\n",
    "                    imgName = videoCapResult.cap_name\n",
    "                    imgName = imgName.split()[0] + \"_\" + chr(\n",
    "                        ord(imgName.split()[1]) + 1)\n",
    "                    imgName += \"_\" + str(videoCapResult.frames)\n",
    "                    frameNames.append(imgName)\n",
    "                    imgName = CONF_VIDEODIR + imgName + \".jpg\"\n",
    "                    cv2.imwrite(imgName, videoCapResult.cur_frame)\n",
    "                    videoCapsJson[videoCapResult.pos].countAtFrame = videoCapResult.countAtFrame\n",
    "                    a = saveJSON()\n",
    "                    if a:\n",
    "                        return a\n",
    "                if not UI_OUTPUT:\n",
    "                    # Add log text to each frame\n",
    "                    log_message = \"Async mode is on.\" if is_async_mode else \\\n",
    "                        \"Async mode is off.\"\n",
    "                    cv2.putText(videoCapResult.cur_frame, log_message, (15, 15),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255),\n",
    "                                1)\n",
    "                    log_message = \"Total {} count: {}\" \\\n",
    "                        .format(videoCapResult.req_label,\n",
    "                                videoCapResult.total_count)\n",
    "                    cv2.putText(videoCapResult.cur_frame, log_message,\n",
    "                                (10, h - 10)\n",
    "                                , cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (255, 255, 255), 1)\n",
    "                    log_message = \"Current {} count: {}\" \\\n",
    "                        .format(videoCapResult.req_label,\n",
    "                                videoCapResult.last_correct_count)\n",
    "                    cv2.putText(videoCapResult.cur_frame, log_message,\n",
    "                                (10, h - 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255),\n",
    "                                1)\n",
    "                    cv2.putText(videoCapResult.cur_frame,\n",
    "                                'Infer wait: %0.3fs' % (\n",
    "                                    infer_duration.total_seconds()),\n",
    "                                (10, h - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (255, 255, 255), 1)\n",
    "\n",
    "                    # Display inferred frame and stats\n",
    "                    stats = numpy.zeros((statsHeight, statsWidth, 1),\n",
    "                                        dtype='uint8')\n",
    "                    for i, log in enumerate(rolling_log):\n",
    "                        cv2.putText(stats, log, (10, i * 20 + 15),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                    (255, 255, 255), 1)\n",
    "                    cv2.imshow(STATS_WINDOW_NAME, stats)\n",
    "                    if idx == 0:\n",
    "                        stats = cv2.cvtColor(stats, cv2.COLOR_GRAY2BGR)\n",
    "                        statsVideo.write(stats)\n",
    "                    end_time = datetime.datetime.now()\n",
    "                    cv2.putText(videoCapResult.cur_frame, 'FPS: %0.2fs'\n",
    "                                % (1 / (\n",
    "                                end_time - videoCapResult.start_time).total_seconds()),\n",
    "                                (10, h - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (255, 255, 255), 1)\n",
    "                    cv2.imshow(videoCapResult.cap_name,\n",
    "                               videoCapResult.cur_frame)\n",
    "                    videoCapResult.start_time = datetime.datetime.now()\n",
    "                    videoCapResult.video.write(videoCapResult.cur_frame)\n",
    "\n",
    "            # Wait if necessary for the required time\n",
    "            key = cv2.waitKey(1)\n",
    "\n",
    "            # Esc key pressed\n",
    "            if key == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                infer_network.clean()\n",
    "                print(\"Finished\")\n",
    "                return\n",
    "            # Tab key pressed\n",
    "            if key == 9:\n",
    "                is_async_mode = not is_async_mode\n",
    "                print(\"Switched to {} mode\".format(\n",
    "                    \"async\" if is_async_mode else \"sync\"))\n",
    "\n",
    "            if is_async_mode:\n",
    "                # Swap infer request IDs\n",
    "                cur_request_id, next_request_id = next_request_id, cur_request_id\n",
    "\n",
    "            # Loop video if LOOP_VIDEO = True and input isn't live from USB camera\n",
    "            if LOOP_VIDEO and not videoCapInfer.is_cam:\n",
    "                vfps = int(round(videoCapInfer.cap.get(cv2.CAP_PROP_FPS)))\n",
    "                # If a video capture has ended restart it\n",
    "                if (videoCapInfer.cur_frame_count >\n",
    "                        videoCapInfer.cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "                        - int(round(vfps / minFPS))):\n",
    "                    videoCapInfer.cur_frame_count = 0\n",
    "                    videoCapInfer.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "        if False not in no_more_data:\n",
    "            break\n",
    "\n",
    "    infer_network.clean()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
